{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: Normalize or enhance input images to reduce irrelevant variations.\n",
    "\n",
    "Data Augmentation: Simulate unseen conditions by augmenting the training data with various transformations.\n",
    "\n",
    "Modern Architecture Components: Incorporate max pooling, ReLU, dropout, or even spatial transformers to improve invariance and generalization.\n",
    "\n",
    "New Training Strategies: Use modern optimization techniques and potentially curriculum learning.\n",
    "\n",
    "Evaluation on Transformed Validation Set: Confirm improvements in robustness by testing on data that simulates unseen conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemented in LeNet5_2.py\n",
    "\n",
    "- Use ReLU instead of scaled tanh.\n",
    "- Replace AvgPool2d with MaxPool2d.\n",
    "- Introduce a Dropout layer before the fully connected layer.\n",
    "- Use a final linear layer with a softmax output (via nn.CrossEntropyLoss) instead of the RBF output and custom loss.\n",
    "\n",
    "### Implemented in data.py\n",
    "\n",
    "- RandomRotation and RandomAffine\n",
    "- Simpler normalization\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
